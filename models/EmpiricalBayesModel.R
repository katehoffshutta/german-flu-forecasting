EmpiricalBayesModel <- R6Class(
  inherit = ContestModel, # or AggregateModel
  private = list(
  
  # attributes
  .nTransformations = 1000, # number of transformations of each historical season to generate the prior
  .verbose = F,
  .hyperparams = data.frame("mu_m" = rep(1,16), # default min peak week param
                            "mu_M" = rep(52,16), # default max peak week param
                            "theta_m" = rep(0.9,16), # default min peak wILI height param
                            "theta_M" = rep(1.1,16), # default max peak wILI height param
                            "b_r" = rep(.03,16), # default CDC baseline 
                            "nu_m" = rep(0.75,16), # default min pacing param
                            "nu_M" = rep(1.25,16), # default max pacing param
                            "region" = c(1:16)# Will tell us the region associated with each hyperparam
                            #"sigma" = 1 # Removed because it'll be a vector.
  ),
  .ciLower = NULL, # wald lower
  .ciUpper = NULL,  # wald upper 95
  .fitSigma = NULL, # DF of sigmas and regions generated by the training data fit
  .historicalData = NULL,
  .filteredData = NULL, # this is a data frame, first column is region, second column year, rest are season weeks
  .testData = NULL,
  .currentData = NULL, #yrs curr
  .prior = NULL, #frs 
  .priorRegions = NULL,
  .priorYears = NULL,
  .priorSigma = NULL, # These are extracted along with the priors
  .posterior = NULL, # made this the potential forcasts (posterior multiplied by weights)
  .posteriorMedian = NULL, # posterior multiplied by median of weights
  .posterior50Lower = NULL, # posterior multiplied by lower bound of weights
  .posterior50Upper = NULL, # posterior multiplied by upper bound of weights
  .seed = 7, # the default seed is 7 (or perhaps sample the seed if the user doesn't define one)
  .weights = NULL, # weights
  .unweightedPosterior = NULL, # posterior estimates without weights
  .regions = NULL,
  .variance = NULL,
  
  .forecast = NULL, # returns a 1 x 52 IncidenceMatrix for now
  .forecastMedian = NULL, # IM for Median
  .forecast50LB = NULL, # IM for 50% CI Lower Bound
  .forecast50UB = NULL, # IM for 50% CI Upper Bound
  .forecastObject = NULL, # ForecastFramework::Forecast 
  # methods
  
  .gatherData = function(incmat){
    print("[.gatherData]")
    incdat <- data.frame(as.table(t(incmat))) %>% #$mat))) %>%
      rename(textdate = Var1, location = Var2, value=Freq) %>%
      mutate(
        year = as.numeric(substr(textdate, 2, 5)),
        epiweek = as.numeric(substr(textdate, 8, 9)),
        date = MMWRweek::MMWRweek2Date(year, epiweek)
      ) %>% 
      filter(!(year == 2015 & epiweek == 26)) %>% 
      filter(!(year == 2009 & epiweek == 26)) %>% 
      filter(!(year == 2004 & epiweek == 26)) %>% 
      mutate(season_week = epiweek - 26) %>% 
      mutate(season_year = as.character(year))
    incdat$season_week <- ifelse(incdat$season_week <= 0, incdat$season_week + 53, incdat$season_week)
    incdat$season_year <- ifelse(incdat$season_week <= 26,
                                 paste0(incdat$season_year, "-", as.character(as.numeric(incdat$season_year) + 1)),
                                 paste0(as.character(as.numeric(incdat$season_year) - 1), "-", incdat$season_year))
    return(incdat) 
  }
  ,
  
  .weightedVariance = function(vec, wts){
    m_star <- weighted.mean(vec, wts)
    wvar <- sum(wts*(vec-m_star)^2)
    return(wvar)
  },
  
  .extractShapesAndHyperparams = function(){
    print("[.extractShapesAndHyperparams]"); 
    require(genlasso)
    require(tidyverse)
    require(zoo)
    require(MMWRweek)
    
    training_data <- private$.historicalData;
    private$.regions <- training_data$rnames;
    
    training_data_long <- private$.gatherData(incmat = training_data$mat)
    
    # here is where you can define the training and test data
    dat <- training_data_long  #%>% filter(season_year %in% c("2004-2005","2005-2006")) #,"2008-2009","2009-2010","2010-2011","2011-2012","2012-2013","2014-2015"))
    #private$.testData = training_data_long %>% filter(season_year %in% c("2006-2007")) # test on all cities for the years selected
    
    output_peak_height <- vector()
    output_peak_week <- vector()
    output_qt_trajectories <- data.frame(1:52)
    colnames(output_qt_trajectories) <- "season_week"
    
    regions = c()
    seasonYears = c()
    mu_ms = c()
    mu_Ms = c()
    theta_ms = c()
    theta_Ms = c()
    sigmas <- c()
    
    for(L in unique(dat$location)){
      
      output_peak_height <- vector()
      output_peak_week <- vector()
      this_region_sigmas <- vector() 
      
      for(Y in unique(dat$season_year)){
        
        temp_dat <- dat %>% filter(season_year == Y) %>% filter(location == L) %>% arrange(season_week)
        if((length(temp_dat$value) < 10)){
          print("not enough data in this season. skip")
          next
        }
        
        curr_peak_height <- max(temp_dat$value)
        curr_peak_season_week <- temp_dat$season_week[which(curr_peak_height == temp_dat$value)]
        
        output_peak_height <- c(output_peak_height, curr_peak_height)
        output_peak_week <- c(output_peak_week, curr_peak_season_week)
        
        qtf <- trendfilter(y  = temp_dat$value, pos = temp_dat$season_week, ord = 2)
        cv <- cv.trendfilter(qtf, k = 5, verbose = F)  # cv$lambda.1se # plot(qtf, lambda = cv$lambda.1se)
        
        output_qt_values <- predict(qtf, lambda = cv$lambda.1se)$fit
        this_year_and_region_residual_sd <- sd(temp_dat$value - output_qt_values)
        
        interpolated_qt_values <- pmax(predict(qtf, lambda = cv$lambda.1se)$fit, 0)
        
        this_region_sigmas <- c(this_region_sigmas, this_year_and_region_residual_sd)
        
        week <- as.data.frame(1:52)
        colnames(week) <- "season_week"
        vals <- cbind.data.frame(temp_dat$season_week, interpolated_qt_values)
        colnames(vals) <- c("season_week", "qt_val")
        output <- left_join(week, vals, by = "season_week") %>% mutate(qt_val = na.approx(qt_val, na.rm = F))
        if(is.na(output$qt_val[52])){
          output$qt_val[52] <- max(output$qt_val[51] + (output$qt_val[51] - output$qt_val[50]), 0)
        }
        if(is.na(output$qt_val[1])){
          output$qt_val[1] <- max(output$qt_val[2] - (output$qt_val[3] - output$qt_val[2]), 0)
        }
        
        output_qt_trajectories <- cbind(output_qt_trajectories, trajectory = output$qt_val)
        regions = c(regions, L)
        seasonYears = c(seasonYears,Y)
      } # end loop over season years
      
      
      sigmas <- cbind(sigmas, this_region_sigmas)
      
      mu_ms <- c(mu_ms,min(output_peak_week)) # min peak week
      mu_Ms <- c(mu_Ms,max(output_peak_week)) # max peak week
      theta_ms <- c(theta_ms,min(output_peak_height)) # min peak wILI height param
      theta_Ms <- c(theta_Ms,max(output_peak_height))
      
    } # end loop over regions
    
    # Make candidate trajectories rows, not columns, to match other objects
    output_qt_trajectories <- t(output_qt_trajectories[,-1])
    output_qt_trajectories = cbind.data.frame(regions,seasonYears, output_qt_trajectories)
    colnames(output_qt_trajectories) <- c("region","year",c(1:52));
    
    private$.filteredData <- output_qt_trajectories
    
    private$.hyperparams$mu_m <- mu_ms; #min(output_peak_week) # min peak week
    private$.hyperparams$mu_M <- mu_Ms; #max(output_peak_week) # max peak week
    private$.hyperparams$theta_m <- theta_ms; #min(output_peak_height) # min peak wILI height param
    private$.hyperparams$theta_M <- theta_Ms; #max(output_peak_height) # max peak wILI height param 
    private$.hyperparams$region <- unique(dat$location)
    
    sigmas_with_regions <- data.frame(as.numeric(sigmas), regions)
    colnames(sigmas_with_regions) <- c("sigma", "region")
    private$.fitSigma <- sigmas_with_regions # was: output_noise_sd # TODO maybe needs fixing still!
    
  }
  ,
  
  .generatePrior = function(){
    
    print("[.generatePrior]");
    
    # initialize matrix that will go into private$.prior
    priorMat = matrix(rep(NA,private$.nTransformations*52), ncol=52,byrow=T);
    
    regions = c();
    sigmas = matrix(NA, ncol = 1, nrow = private$.nTransformations)
    set.seed(private$.seed)
    
    for(k in c(1:private$.nTransformations))
    {
      # note that here we do not sample within regions, I'm just assuming that because the
      # sampling is random, each region gets approximately the same number of entries
      # in its prior
      f_r_index = sample(1:nrow(private$.filteredData),1);# draw shape index
      regions = c(regions,as.character(private$.filteredData[f_r_index,]$region))
      
      this_mu_m = private$.hyperparams$mu_m[which(private$.hyperparams$region == private$.filteredData[f_r_index,]$region)]
      this_mu_M = private$.hyperparams$mu_M[which(private$.hyperparams$region == private$.filteredData[f_r_index,]$region)]
      
      this_theta_m = private$.hyperparams$theta_m[which(private$.hyperparams$region == private$.filteredData[f_r_index,]$region)]
      this_theta_M = private$.hyperparams$theta_M[which(private$.hyperparams$region == private$.filteredData[f_r_index,]$region)]
      
      mu_r = sample(this_mu_m:this_mu_M,1)# draw peak week
      theta_r = runif(1,this_theta_m, this_theta_M) # draw peak height
      
      # Stuff that's not region-specific
      b_r = private$.hyperparams$b_r[1]; # find cdc baseline wILI for the year - not implemented yet
      nu_r = runif(1,private$.hyperparams$nu_m[1], private$.hyperparams$nu_M[1]) # draw pacing
      
      # TODO I'm not sure if this is supposed to be region-specific? Or if it's also random
      # NOTE: Josh modified line below; please check that it's behaving as advised.
      sigmas[k,1] <- sample(private$.fitSigma[private$.fitSigma$region == private$.filteredData[f_r_index,]$region,1], size = 1, replace = TRUE)
      # print(paste0("sigmas [k,1] is ",sigmas[k,1]))
      
      if (private$.verbose == T)
      {
        print("[fit] Prior draws:")
        print(paste("season index:",f_r_index))
        print(paste("peak week shift: ",mu_r))
        print(paste("peak height: ",theta_r))
        print(paste("cdc baseline: ",b_r))
        print(paste("pacing:",nu_r))
      };
      
      f_r = as.matrix(private$.filteredData[f_r_index,c(3:54)])
      f_r_transf = c();
      
      for(i in c(1:length(f_r))){ 
        index = round((i - mu_r)/nu_r + which(f_r==max(f_r)));
        if(index < 1) index = 1; # TODO
        if(index > length(f_r)) index = length(f_r); # TODO
        f_r_transf = c(f_r_transf,b_r + (theta_r - b_r)/(max(f_r) - b_r)*(f_r[index]));
      }
      
      priorMat[k,] = f_r_transf;
    }
    
    private$.priorRegions = regions;
    private$.prior = priorMat;
    private$.priorSigma <- sigmas;
    
  },
  
  .generatePosterior = function(){
    
    print("[.generatePosterior]");
    
    private$.weights = matrix(NA, nrow = private$.nTransformations, ncol = 1)
    private$.unweightedPosterior = data.frame(matrix(NA, private$.nTransformations, 52))
    
    set.seed(private$.seed)
    
    yrs_curr_regions = private$.currentData$rnames;
    frs_curr = private$.prior
    
    for(i in c(1:nrow(private$.currentData$mat)))  
    {
      
      frs_curr_inx = which(private$.priorRegions == yrs_curr_regions[i])
      yrs_curr = private$.currentData$mat[i,]
      
      for (j in 1:length(frs_curr_inx)){
        
        frs_curr = private$.prior[frs_curr_inx[j],]
        sigma <- private$.priorSigma[frs_curr_inx[j]]
        
        # try different method weighted by weeks in season
        weight = 0
        for (k in 1:length(yrs_curr))
        {
          weight = weight+log(1.1^k*dnorm(yrs_curr[k],mean=frs_curr[k],sd=5*sigma))
        }
        
        v_1 = c()
        for(a in c(1:length(yrs_curr))){
          v_1[a] = yrs_curr[a]
        }
        for(b in (length(yrs_curr)+1):52){
          v_1[b] = frs_curr[b]
        }
        
        private$.weights[frs_curr_inx[j]] = exp(weight)
        private$.unweightedPosterior[frs_curr_inx[j],] = v_1
        
      } # end iteration over prior
      
    } # end iteration over region
    
  },
  
  .calculateForecast = function(){
    
    print("[.calculateForecast]")
    private$.posterior = data.frame(matrix(NA, private$.nTransformations, 52));
    
    # posterior CI's
    private$.posterior50Lower = data.frame(matrix(NA, private$.nTransformations, 52));
    private$.posterior50Upper = data.frame(matrix(NA, private$.nTransformations, 52));
    private$.posteriorMedian = data.frame(matrix(NA, private$.nTransformations, 52));
    
    forecast = data.frame(matrix(NA, nrow(private$.currentData$mat), 52));
    variance = data.frame(matrix(NA, nrow(private$.currentData$mat), 52));
    
    forecastMedian = data.frame(matrix(NA, nrow(private$.currentData$mat), 52));
    forecast50Lower = data.frame(matrix(NA, nrow(private$.currentData$mat), 52));
    forecast50Upper = data.frame(matrix(NA, nrow(private$.currentData$mat), 52));
    
    # within each region, normalize the weight and multiply it by the unweighted posterior
    for(i in c(1:nrow(private$.currentData$mat)))
    {
      
      post_inx = which(private$.priorRegions == private$.currentData$rnames[i])
      
      #private$.weights = private$.weights/sum(na.omit(private$.weights))
      private$.weights[post_inx] = private$.weights[post_inx]/sum(private$.weights[post_inx])
      
      ## TRYING SOMETHING
      wMedian = quantile(private$.weights[post_inx],0.5)
      w50Lower = quantile(private$.weights[post_inx],0.25)
      w50Upper = quantile(private$.weights[post_inx],0.75)
      
      print(paste("Weight sum for region: ", private$.currentData$rnames[i]))
      print(sum(private$.weights[post_inx]))
      for(j in c(1:length(post_inx))){
        private$.posterior[post_inx[j],] = private$.weights[post_inx[j],1] * private$.unweightedPosterior[post_inx[j],]
        # median
        private$.posteriorMedian[post_inx[j],] = wMedian * private$.unweightedPosterior[post_inx[j],]
        # 50% CI
        private$.posterior50Lower[post_inx[j],] = w50Lower * private$.unweightedPosterior[post_inx[j],]
        private$.posterior50Upper[post_inx[j],] = w50Upper * private$.unweightedPosterior[post_inx[j],]
      }
      
      forecastRow = as.matrix(apply(private$.posterior[post_inx,],2,sum))
      forecast[i,] = forecastRow; 
      
      varianceRow = as.matrix(apply(private$.unweightedPosterior[post_inx,], 2, private$.weightedVariance, wts = private$.weights[post_inx]))
      variance[i,] = varianceRow;
      
      forecastMedianRow = as.matrix(apply(private$.posteriorMedian[post_inx,],2,sum))
      forecastMedian[i,] = forecastMedianRow
      
      forecast50LRow = as.matrix(apply(private$.posterior50Lower[post_inx,],2,sum))
      forecast50Lower[i,] = forecast50LRow
      forecast50URow = as.matrix(apply(private$.posterior50Upper[post_inx,],2,sum))
      forecast50Upper[i,] = forecast50URow
    }
    
    
    # store it all in private$.forecast, where rows are regions and cols are weighted avg.
    private$.forecast = IncidenceMatrix$new(data = forecast);
    # trying 50% CI
    private$.forecastMedian = IncidenceMatrix$new(data = forecastMedian)
    private$.forecast50LB = IncidenceMatrix$new(data = forecast50Lower)
    private$.forecast50UB = IncidenceMatrix$new(data = forecast50Upper)
    
    private$.forecast$rnames = private$.currentData$rnames;
    private$.forecastMedian$rnames = private$.currentData$rnames;
    private$.forecast50LB$rnames = private$.currentData$rnames;
    private$.forecast50UB$rnames = private$.currentData$rnames;
    
    private$.forecastObject = ForecastFramework::Forecast$new(data = forecast)
    
    private$.variance = IncidenceMatrix$new(data = variance);
    private$.variance$rnames = private$.currentData$rnames;
    
    private$.ciLower = private$.forecast$mat - 1.96*sqrt(private$.variance$mat);
    private$.ciUpper = private$.forecast$mat + 1.96*sqrt(private$.variance$mat);
    
  }
  
),

public = list(
  
  # attributes
  data = NULL,
  newdata = NULL,
  
  # methods
  
  fit = function(fitData,n=1000, steps=6,verbose=F){
    
    print("[fit]")
    
    # debug line from Katie
    if("fit" %in% private$.debug){browser()};
    
    # assign private attribute for number of transformations and historical data
    private$.nTransformations <- n;
    private$.historicalData <- fitData;
    
    # call .extractShapesAndHyperparams
    private$.extractShapesAndHyperparams();
    
    # call .generatePrior
    private$.generatePrior();
    
  },
  
  forecast = function(newdata, steps = 6){
    
    print("[forecast]")
    # subset the data to current season only
    last_sw = tail(newdata$colData$season.week,1)
    first_inx = ncol(newdata$mat) - last_sw
    last_inx = ncol(newdata$mat)
    newdata$subset(cols = first_inx:last_inx);
    private$.currentData = newdata
    
    # call .generatePosterior
    private$.generatePosterior();
    # call .calculateForecast()
    private$.calculateForecast();
    # return forecast object
    return(private$.forecastObject);
    
  },
  
  
  plotPrior = function(indices=c(1:private$.nTransformations)){
    plot(private$.prior[indices[1],], xlim=c(0,52),ylim=c(0, max(private$.prior[indices,])),type="l",col=rainbow(length(indices))[1],xlab = "Season Week",ylab="wILI", main="Prior");
    for(i in c(2:length(indices))) {lines(private$.prior[indices[i],],col=rainbow(length(indices))[i])};
  },
  plotPosterior = function(indices=c(1:nrow(private$.posterior))){
    d = as.matrix(private$.posterior)
    plot(d[indices[1],], xlim=c(0,52),ylim=c(0,50),type="l",col=rainbow(length(indices))[1],xlab = "Season Week",ylab="wILI", main="Posterior");
    for(i in c(2:length(indices))) {lines(d[indices[i],],col=rainbow(length(indices))[i])};
  },
  
  getHistoricalData = function(){return(private$.historicalData)},
  getFilteredData = function(){return(private$.filteredData)},
  getPrior = function(){return(private$.prior)},
  getHyperparams = function(){return(private$.hyperparams)},
  getSigmas = function(){return(private$.priorSigma)},
  getFitSigmas = function(){return(private$.fitSigma)},
  getCurrentData = function(){return(private$.currentData)},
  getWeights = function(){return(private$.weights)},
  getUnweightedPosterior = function(){return(private$.unweightedPosterior)},
  getPosterior = function(){return(private$.posterior)},
  getForecast = function(){return(private$.forecast)},
  getForecast50LB = function(){return(private$.forecast50LB)},
  getForecast50UB = function(){return(private$.forecast50UB)},
  getForecastMedian = function(){return(private$.forecastMedian)},
  getTestData = function(){return(private$.testData)},
  getRegions = function(){return(private$.regions)},
  getPriorRegions = function(){return(private$.priorRegions)},
  getVariance = function(){return(private$.variance)},
  getCILower = function(){return(private$.ciLower)},
  getCIUpper = function(){return(private$.ciUpper)},
  initialize = function(){}
)
)